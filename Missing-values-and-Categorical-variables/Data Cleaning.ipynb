{"cells":[{"metadata":{},"cell_type":"markdown","source":"   ![](http://dataanalyticsedge.com/wp-content/uploads/2018/05/img2.jpeg)"},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning with Python"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"Data Cleaning is the process of transforming raw data into consistent data that can be analyzed. It is aimed at improving the content of statistical statements based on the data as well as their reliability. Data cleaning may profoundly influence the statistical statements based on the data."},{"metadata":{},"cell_type":"markdown","source":"We have to uderstand the difference between categorical and continuous data in the dataset and identifying the type of data.\n"},{"metadata":{},"cell_type":"markdown","source":"Categorical features can only take on a limited, and usually fixed, number of possible values. For example, if a dataset is about information related to users, then you will typically find features like country, gender, age group, etc. Alternatively, if the data you're working with is related to products, you will find features like product type, manufacturer, seller and so on.\nThese are all categorical features in your dataset. These features are typically stored as text values which represent various traits of the observations. For example, gender is described as Male (M) or Female (F), product type could be described as electronics, apparels, food etc."},{"metadata":{},"cell_type":"markdown","source":"Features which have some order associated with them are called ordinal features. For example, a feature like economic status, with three categories: low, medium and high, which have an order associated with them."},{"metadata":{},"cell_type":"markdown","source":"There are also continuous features. These are numeric variables that have an infinite number of values between any two values. A continuous variable can be numeric or a date/time."},{"metadata":{},"cell_type":"markdown","source":"In this raw data, we have a categorical variables which have been encoded to Continuous variables for analysis. So, our major data cleaning task in here is to take care of the missing values and also to make sure there are no discrepancies in the encoded data."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/food-choices/food_coded.csv\n/kaggle/input/food-choices/codebook_food.docx\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/food-choices/food_coded.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail(10)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"       GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n115    3.3       2          1               610           4.0           980.0   \n116    3.4       1          1               610           NaN           420.0   \n117   3.77       1          1               610           NaN           315.0   \n118   3.63       1          1               430           3.0           420.0   \n119    3.2       2          1               610           3.0           420.0   \n120    3.5       1          1               610           4.0           420.0   \n121      3       1          1               265           2.0           315.0   \n122  3.882       1          1               720           NaN           420.0   \n123      3       2          1               720           4.0           420.0   \n124    3.9       1          1               430           NaN           315.0   \n\n     coffee                                       comfort_food  \\\n115       2  chocolate bar, ice cream, pretzels, potato chi...   \n116       2             Ice cream, chocolate, pizza, cucumber    \n117       2  Noodle ( any kinds of noodle), Tuna sandwich, ...   \n118       1                               Chinese, chips, cake   \n119       2                        chips, rice, chicken curry,   \n120       2            wine. mac and cheese, pizza, ice cream    \n121       2                         Pizza / Wings / Cheesecake   \n122       1                         rice, potato, seaweed soup   \n123       1                       Mac n Cheese, Lasagna, Pizza   \n124       2                       Chocolates, pizza, and Ritz.   \n\n                                  comfort_food_reasons  \\\n115              Stress, boredom and physical activity   \n116                     loneliness, homework, boredom    \n117  When i'm  eating with my close friends/ Food s...   \n118                                Stress and boredom    \n119                   Happiness, boredom, social event   \n120                               boredom and sadness    \n121                    Loneliness / Homesick / Sadness   \n122                                            sadness   \n123      happiness, they are some of my favorite foods   \n124                   hormones, Premenstrual syndrome.   \n\n     comfort_food_reasons_coded  ...  soup  sports  thai_food  \\\n115                         NaN  ...   1.0     1.0          1   \n116                         NaN  ...   1.0     2.0          5   \n117                         NaN  ...   1.0     2.0          5   \n118                         NaN  ...   1.0     2.0          4   \n119                         NaN  ...   1.0     1.0          5   \n120                         NaN  ...   1.0     1.0          5   \n121                         NaN  ...   1.0     NaN          4   \n122                         NaN  ...   1.0     2.0          5   \n123                         NaN  ...   2.0     2.0          1   \n124                         NaN  ...   1.0     2.0          2   \n\n    tortilla_calories  turkey_calories              type_sports veggies_day  \\\n115            1165.0              690                   Hockey           2   \n116             725.0              345                     none           5   \n117             725.0              690  No, I don't play sport.           3   \n118             940.0              345                     None           5   \n119            1165.0              690                   Soccer           5   \n120             940.0              500                 Softball           5   \n121             940.0              500              basketball            5   \n122             580.0              690                     none           4   \n123             940.0              500                      NaN           3   \n124             725.0              345                      NaN           4   \n\n     vitamins  waffle_calories  weight  \n115         2             1315     150  \n116         1             1315     170  \n117         1              760     113  \n118         2             1315     140  \n119         2             1315     185  \n120         1             1315     156  \n121         2             1315     180  \n122         2             1315     120  \n123         1             1315     135  \n124         2              575     135  \n\n[10 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GPA</th>\n      <th>Gender</th>\n      <th>breakfast</th>\n      <th>calories_chicken</th>\n      <th>calories_day</th>\n      <th>calories_scone</th>\n      <th>coffee</th>\n      <th>comfort_food</th>\n      <th>comfort_food_reasons</th>\n      <th>comfort_food_reasons_coded</th>\n      <th>...</th>\n      <th>soup</th>\n      <th>sports</th>\n      <th>thai_food</th>\n      <th>tortilla_calories</th>\n      <th>turkey_calories</th>\n      <th>type_sports</th>\n      <th>veggies_day</th>\n      <th>vitamins</th>\n      <th>waffle_calories</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>115</th>\n      <td>3.3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>610</td>\n      <td>4.0</td>\n      <td>980.0</td>\n      <td>2</td>\n      <td>chocolate bar, ice cream, pretzels, potato chi...</td>\n      <td>Stress, boredom and physical activity</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1165.0</td>\n      <td>690</td>\n      <td>Hockey</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1315</td>\n      <td>150</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>3.4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>610</td>\n      <td>NaN</td>\n      <td>420.0</td>\n      <td>2</td>\n      <td>Ice cream, chocolate, pizza, cucumber</td>\n      <td>loneliness, homework, boredom</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>725.0</td>\n      <td>345</td>\n      <td>none</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1315</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>3.77</td>\n      <td>1</td>\n      <td>1</td>\n      <td>610</td>\n      <td>NaN</td>\n      <td>315.0</td>\n      <td>2</td>\n      <td>Noodle ( any kinds of noodle), Tuna sandwich, ...</td>\n      <td>When i'm  eating with my close friends/ Food s...</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>725.0</td>\n      <td>690</td>\n      <td>No, I don't play sport.</td>\n      <td>3</td>\n      <td>1</td>\n      <td>760</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>118</th>\n      <td>3.63</td>\n      <td>1</td>\n      <td>1</td>\n      <td>430</td>\n      <td>3.0</td>\n      <td>420.0</td>\n      <td>1</td>\n      <td>Chinese, chips, cake</td>\n      <td>Stress and boredom</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>940.0</td>\n      <td>345</td>\n      <td>None</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1315</td>\n      <td>140</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>3.2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>610</td>\n      <td>3.0</td>\n      <td>420.0</td>\n      <td>2</td>\n      <td>chips, rice, chicken curry,</td>\n      <td>Happiness, boredom, social event</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>1165.0</td>\n      <td>690</td>\n      <td>Soccer</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1315</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>3.5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>610</td>\n      <td>4.0</td>\n      <td>420.0</td>\n      <td>2</td>\n      <td>wine. mac and cheese, pizza, ice cream</td>\n      <td>boredom and sadness</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>940.0</td>\n      <td>500</td>\n      <td>Softball</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1315</td>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>265</td>\n      <td>2.0</td>\n      <td>315.0</td>\n      <td>2</td>\n      <td>Pizza / Wings / Cheesecake</td>\n      <td>Loneliness / Homesick / Sadness</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>940.0</td>\n      <td>500</td>\n      <td>basketball</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1315</td>\n      <td>180</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>3.882</td>\n      <td>1</td>\n      <td>1</td>\n      <td>720</td>\n      <td>NaN</td>\n      <td>420.0</td>\n      <td>1</td>\n      <td>rice, potato, seaweed soup</td>\n      <td>sadness</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>580.0</td>\n      <td>690</td>\n      <td>none</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1315</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>720</td>\n      <td>4.0</td>\n      <td>420.0</td>\n      <td>1</td>\n      <td>Mac n Cheese, Lasagna, Pizza</td>\n      <td>happiness, they are some of my favorite foods</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>940.0</td>\n      <td>500</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1315</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>3.9</td>\n      <td>1</td>\n      <td>1</td>\n      <td>430</td>\n      <td>NaN</td>\n      <td>315.0</td>\n      <td>2</td>\n      <td>Chocolates, pizza, and Ritz.</td>\n      <td>hormones, Premenstrual syndrome.</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>725.0</td>\n      <td>345</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>2</td>\n      <td>575</td>\n      <td>135</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 61 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"Index(['GPA', 'Gender', 'breakfast', 'calories_chicken', 'calories_day',\n       'calories_scone', 'coffee', 'comfort_food', 'comfort_food_reasons',\n       'comfort_food_reasons_coded', 'cook', 'comfort_food_reasons_coded.1',\n       'cuisine', 'diet_current', 'diet_current_coded', 'drink',\n       'eating_changes', 'eating_changes_coded', 'eating_changes_coded1',\n       'eating_out', 'employment', 'ethnic_food', 'exercise',\n       'father_education', 'father_profession', 'fav_cuisine',\n       'fav_cuisine_coded', 'fav_food', 'food_childhood', 'fries', 'fruit_day',\n       'grade_level', 'greek_food', 'healthy_feeling', 'healthy_meal',\n       'ideal_diet', 'ideal_diet_coded', 'income', 'indian_food',\n       'italian_food', 'life_rewarding', 'marital_status',\n       'meals_dinner_friend', 'mother_education', 'mother_profession',\n       'nutritional_check', 'on_off_campus', 'parents_cook', 'pay_meal_out',\n       'persian_food', 'self_perception_weight', 'soup', 'sports', 'thai_food',\n       'tortilla_calories', 'turkey_calories', 'type_sports', 'veggies_day',\n       'vitamins', 'waffle_calories', 'weight'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Let us start with checking the columns with missing values and dealing with them.\nIf we take a closer look at the data, each column must be of a certain datatype and you will find bogus data. \n\nWe will deal with both missing values and clean the data by checking on datatypes as well."},{"metadata":{},"cell_type":"markdown","source":"We are creating a list of columns which have missing values followed by the number of missing values in each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing = [col for col in df.columns\n                     if df[col].isnull().any()]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cols_with_missing:\n    print(i,df[i].isnull().sum())","execution_count":6,"outputs":[{"output_type":"stream","text":"GPA 2\ncalories_day 19\ncalories_scone 1\ncomfort_food 1\ncomfort_food_reasons 1\ncomfort_food_reasons_coded 19\ncook 3\ncuisine 17\ndiet_current 1\ndrink 2\neating_changes 3\nemployment 9\nexercise 13\nfather_education 1\nfather_profession 3\nfav_cuisine 2\nfav_food 2\nfood_childhood 1\nhealthy_meal 1\nideal_diet 1\nincome 1\nlife_rewarding 1\nmarital_status 1\nmeals_dinner_friend 3\nmother_education 3\nmother_profession 2\non_off_campus 1\npersian_food 1\nself_perception_weight 1\nsoup 1\nsports 2\ntortilla_calories 1\ntype_sports 21\nweight 2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(125, 61)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"           Gender   breakfast  calories_chicken  calories_day  calories_scone  \\\ncount  125.000000  125.000000        125.000000    106.000000      124.000000   \nmean     1.392000    1.112000        577.320000      3.028302      505.241935   \nstd      0.490161    0.316636        131.214156      0.639308      230.840506   \nmin      1.000000    1.000000        265.000000      2.000000      315.000000   \n25%      1.000000    1.000000        430.000000      3.000000      420.000000   \n50%      1.000000    1.000000        610.000000      3.000000      420.000000   \n75%      2.000000    1.000000        720.000000      3.000000      420.000000   \nmax      2.000000    2.000000        720.000000      4.000000      980.000000   \n\n          coffee  comfort_food_reasons_coded        cook  \\\ncount  125.00000                  106.000000  122.000000   \nmean     1.75200                    2.698113    2.786885   \nstd      0.43359                    1.972042    1.038351   \nmin      1.00000                    1.000000    1.000000   \n25%      2.00000                    2.000000    2.000000   \n50%      2.00000                    2.000000    3.000000   \n75%      2.00000                    3.000000    3.000000   \nmax      2.00000                    9.000000    5.000000   \n\n       comfort_food_reasons_coded.1     cuisine  ...  persian_food  \\\ncount                    125.000000  108.000000  ...    124.000000   \nmean                       2.688000    1.388889  ...      2.806452   \nstd                        1.910987    0.974759  ...      1.423824   \nmin                        1.000000    1.000000  ...      1.000000   \n25%                        2.000000    1.000000  ...      2.000000   \n50%                        2.000000    1.000000  ...      3.000000   \n75%                        3.000000    1.000000  ...      4.000000   \nmax                        9.000000    6.000000  ...      5.000000   \n\n       self_perception_weight        soup      sports   thai_food  \\\ncount              124.000000  124.000000  123.000000  125.000000   \nmean                 3.120968    1.217742    1.390244    3.336000   \nstd                  1.115980    0.414385    0.489800    1.436528   \nmin                  1.000000    1.000000    1.000000    1.000000   \n25%                  2.000000    1.000000    1.000000    2.000000   \n50%                  3.000000    1.000000    1.000000    3.000000   \n75%                  4.000000    1.000000    2.000000    5.000000   \nmax                  6.000000    2.000000    2.000000    5.000000   \n\n       tortilla_calories  turkey_calories  veggies_day    vitamins  \\\ncount         124.000000       125.000000   125.000000  125.000000   \nmean          947.580645       555.040000     4.008000    1.512000   \nstd           202.090179       152.370379     1.081337    0.501867   \nmin           580.000000       345.000000     1.000000    1.000000   \n25%           725.000000       500.000000     3.000000    1.000000   \n50%           940.000000       500.000000     4.000000    2.000000   \n75%          1165.000000       690.000000     5.000000    2.000000   \nmax          1165.000000       850.000000     5.000000    2.000000   \n\n       waffle_calories  \ncount       125.000000  \nmean       1073.400000  \nstd         248.667092  \nmin         575.000000  \n25%         900.000000  \n50%         900.000000  \n75%        1315.000000  \nmax        1315.000000  \n\n[8 rows x 47 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>breakfast</th>\n      <th>calories_chicken</th>\n      <th>calories_day</th>\n      <th>calories_scone</th>\n      <th>coffee</th>\n      <th>comfort_food_reasons_coded</th>\n      <th>cook</th>\n      <th>comfort_food_reasons_coded.1</th>\n      <th>cuisine</th>\n      <th>...</th>\n      <th>persian_food</th>\n      <th>self_perception_weight</th>\n      <th>soup</th>\n      <th>sports</th>\n      <th>thai_food</th>\n      <th>tortilla_calories</th>\n      <th>turkey_calories</th>\n      <th>veggies_day</th>\n      <th>vitamins</th>\n      <th>waffle_calories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>125.000000</td>\n      <td>125.000000</td>\n      <td>125.000000</td>\n      <td>106.000000</td>\n      <td>124.000000</td>\n      <td>125.00000</td>\n      <td>106.000000</td>\n      <td>122.000000</td>\n      <td>125.000000</td>\n      <td>108.000000</td>\n      <td>...</td>\n      <td>124.000000</td>\n      <td>124.000000</td>\n      <td>124.000000</td>\n      <td>123.000000</td>\n      <td>125.000000</td>\n      <td>124.000000</td>\n      <td>125.000000</td>\n      <td>125.000000</td>\n      <td>125.000000</td>\n      <td>125.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.392000</td>\n      <td>1.112000</td>\n      <td>577.320000</td>\n      <td>3.028302</td>\n      <td>505.241935</td>\n      <td>1.75200</td>\n      <td>2.698113</td>\n      <td>2.786885</td>\n      <td>2.688000</td>\n      <td>1.388889</td>\n      <td>...</td>\n      <td>2.806452</td>\n      <td>3.120968</td>\n      <td>1.217742</td>\n      <td>1.390244</td>\n      <td>3.336000</td>\n      <td>947.580645</td>\n      <td>555.040000</td>\n      <td>4.008000</td>\n      <td>1.512000</td>\n      <td>1073.400000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.490161</td>\n      <td>0.316636</td>\n      <td>131.214156</td>\n      <td>0.639308</td>\n      <td>230.840506</td>\n      <td>0.43359</td>\n      <td>1.972042</td>\n      <td>1.038351</td>\n      <td>1.910987</td>\n      <td>0.974759</td>\n      <td>...</td>\n      <td>1.423824</td>\n      <td>1.115980</td>\n      <td>0.414385</td>\n      <td>0.489800</td>\n      <td>1.436528</td>\n      <td>202.090179</td>\n      <td>152.370379</td>\n      <td>1.081337</td>\n      <td>0.501867</td>\n      <td>248.667092</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>265.000000</td>\n      <td>2.000000</td>\n      <td>315.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>580.000000</td>\n      <td>345.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>575.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>430.000000</td>\n      <td>3.000000</td>\n      <td>420.000000</td>\n      <td>2.00000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>725.000000</td>\n      <td>500.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>900.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>610.000000</td>\n      <td>3.000000</td>\n      <td>420.000000</td>\n      <td>2.00000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>940.000000</td>\n      <td>500.000000</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>900.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>720.000000</td>\n      <td>3.000000</td>\n      <td>420.000000</td>\n      <td>2.00000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>1165.000000</td>\n      <td>690.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>1315.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>720.000000</td>\n      <td>4.000000</td>\n      <td>980.000000</td>\n      <td>2.00000</td>\n      <td>9.000000</td>\n      <td>5.000000</td>\n      <td>9.000000</td>\n      <td>6.000000</td>\n      <td>...</td>\n      <td>5.000000</td>\n      <td>6.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>1165.000000</td>\n      <td>850.000000</td>\n      <td>5.000000</td>\n      <td>2.000000</td>\n      <td>1315.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 47 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We now take a clos look at the data and try to replace the missiing values using **fillna()** function. We filter down the columns with lots of missing values and manually replace them with values which is more relevant. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['calories_day'].fillna(1,inplace=True)\ndf['comfort_food_reasons_coded'].fillna(9,inplace=True)\ndf['cuisine'].fillna(6,inplace=True)\ndf['employment'].fillna(4,inplace=True)\ndf['exercise'].fillna(5,inplace=True)\ndf['type_sports'].fillna('Nothing',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Followed by that, we remove the rows with missing values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in cols_with_missing:\n    df = df[~df[i].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The GPA column contains float values in string format along with missing values and bogus values.\n\nTo deal with this problem we create a new column by first removing the '.'(decimal point) from the values, in order to make use of the **.isdigit()** function. This function helps you to identify if all the values in the string are digits. \n\nhttps://www.geeksforgeeks.org/python-pandas-series-str-isdigit/\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['GPA'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=['GPA'],inplace=True)\ndf['GPA_new'] = df['GPA'].str.replace(\".\",\"\")\ndf = df[~df['GPA_new'].str.isdigit() == False]\ndf['GPA'] = df['GPA'].astype(float)\ndf.drop('GPA_new',axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use **value_counts()** function to check whether the column values are legit. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['breakfast'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['calories_chicken'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['calories_day'] = df['calories_day'].astype(int)\ndf['calories_day'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['calories_scone'] = df['calories_scone'].astype(int)\ndf['calories_scone'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['coffee'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['comfort_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['comfort_food_reasons'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['comfort_food_reasons_coded'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cook'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cuisine'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diet_current'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diet_current_coded'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['drink'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['eating_changes'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['eating_changes_coded'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['eating_changes_coded1'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['eating_out'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['employment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ethnic_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['exercise'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['father_education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['father_profession'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['fav_cuisine'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['fav_cuisine_coded'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['fav_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['food_childhood'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['fries'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['fruit_day'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['grade_level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['greek_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['healthy_feeling'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['healthy_meal'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['ideal_diet'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ideal_diet_coded'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['income'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['indian_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['italian_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['life_rewarding'] = df['life_rewarding'].astype(int)\ndf['life_rewarding'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['marital_status'] = df['marital_status'].astype(int)\ndf['marital_status'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['meals_dinner_friend'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['mother_education'] = df['mother_education'].astype(int)\ndf['mother_education'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['mother_profession'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['nutritional_check'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['on_off_campus'] = df['on_off_campus'].astype(int)\ndf['on_off_campus'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['parents_cook'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pay_meal_out'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['persian_food'] = df['persian_food'].astype(int)\ndf['persian_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['self_perception_weight'] = df['self_perception_weight'].astype(int)\ndf['self_perception_weight'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['soup'] = df['soup'].astype(int)\ndf['soup'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['sports'] = df['sports'].astype(int)\ndf['sports'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['thai_food'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tortilla_calories'] = df['tortilla_calories'].astype(int)\ndf['tortilla_calories'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['turkey_calories'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['type_sports'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['veggies_day'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['vitamins'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['waffle_calories'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The weight column can be cleaned by using **isdigit()** function. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['weight'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df['weight'].str.isdigit()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After a full fledged cleanup we have a clean dataframe which can be used for analysis."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
